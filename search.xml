<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[Spring4 Security4 Oauth2 in Liferay]]></title>
      <url>%2F2018%2F07%2F05%2Fspring4_security4_oauth2%2F</url>
      <content type="text"><![CDATA[Spring4 Security4 Oauth2 in Liferay标签（Liferay,Spring4,oauth2,security4）： Liferay,Spring4,oauth2,security4]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[CSS vw让overflow:auto页面滚动条出现时不跳动]]></title>
      <url>%2F2017%2F09%2F19%2Fcss_scroll%2F</url>
      <content type="text"><![CDATA[CSS vw让overflow:auto页面滚动条出现时不跳动标签（CSS）： CSShtml {overflow-y: scroll;}:root {overflow-y: auto;overflow-x: hidden;}:root body {position: absolute;}body {width: 100vw;overflow: hidden;}]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[mvn 编译]]></title>
      <url>%2F2017%2F06%2F23%2Fmvn%20info%2F</url>
      <content type="text"><![CDATA[mvn 编译标签（Maven）： Mavenmaven使用exec插件运行Java main方法，以下是3种不同的操作方式。一、从命令行运行1、运行前先编译代码，exec：Java不会自动编译代码，你需要手动执行mvn compile来完成编译。[plain] view plain copymvn compile2、编译完成后，执行exec运行main方法。不需要传递参数：[plain] view plain copymvn exec:java -Dexec.mainClass=”com.vineetmanohar.module.Main”需要传递参数：[plain] view plain copymvn exec:java -Dexec.mainClass=”com.vineetmanohar.module.Main” -Dexec.args=”arg0 arg1 arg2”指定对classpath的运行时依赖：[plain] view plain copymvn exec:java -Dexec.mainClass=”com.vineetmanohar.module.Main” -Dexec.classpathScope=runtime二、在pom.xml中指定某个阶段执行[html] view plain copyorg.codehaus.mojoexec-maven-plugin1.1.1testjavacom.vineetmanohar.module.CodeGeneratorarg0arg1将CodeGenerator.main()方法的执行绑定到maven的 test 阶段，通过下面的命令可以执行main方法：[plain] view plain copymvn test三、在pom.xml中指定某个配置来执行[html] view plain copycode-generatororg.codehaus.mojoexec-maven-plugin1.1.1testjavacom.vineetmanohar.module.CodeGeneratorarg0arg1将2中的配置用标签包裹后就能通过指定该配置文件来执行main方法，如下：[plain] view plain copymvn test -Pcode-generator注：通过以下命令可以获取mvn exec的其他配置参数说明。[plain] view plain copymvn exec:help -Ddetail=true -Dgoal=java英文地址：http://www.vineetmanohar.com/2009/11/3-ways-to-run-java-main-from-maven/]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Nginx 启动]]></title>
      <url>%2F2017%2F05%2F31%2Fnginx-config%2F</url>
      <content type="text"><![CDATA[Nginx 启动标签（Nginx）： Nginx1、Mac下Nginx的启动：[html] view plain copycd usr/local/nginx/sbinsudo ./nginx2、Mac下判断配置文件是否正确[html] view plain copycd /usr/local/nginx/sbinsudo ./nginx -t3、Mac下重启Nginx[html] view plain copycd /usr/local/nginx/sbinsudo ./nginx -s reload4、Mac下Nginx的关闭查询nginx主进程号：ps -ef|grep nginx[html] view plain copy正常停止 sudo kill -QUIT 主进程号快速停止 sudo kill -TERM 主进程号]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[velocity 判断null]]></title>
      <url>%2F2017%2F05%2F10%2Fvelocity_null%2F</url>
      <content type="text"><![CDATA[Velocity 判断 null标签（Velocity）： Velocityvelocity判断是否为null有下面几种方法：1. (! $foo) 判断$foo为空，判断非空为 #if ($foo)```12. ```使用 #ifnull() 或 #ifnotnull() ($foo)```1234 要使用这个特性必须在velocity.properties文件中加入：userdirective = org.apache.velocity.tools.generic.directive.Ifnulluserdirective = org.apache.velocity.tools.generic.directive.Ifnotnull 3. 使用null工具判断 #if($null.isNull($foo)) 1注意这种方式特别有用，尤其你在需要这个判断作为一个判断字句时，比如我要你判断一个集合为null或为空时只能使用这种方式了： $if ($null.isNull($mycoll) || $mycoll.size()==0) ```]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[solr-filter]]></title>
      <url>%2F2017%2F04%2F30%2Fsolr-filter%2F</url>
      <content type="text"><![CDATA[Solr Filter过滤器介绍标签（空格分隔）： solr###Solr的Analyzer分析器、Tokenizer分词器、Filter过滤器的区别/联系本文转自CSDN随-忆Solr Filter过滤器介绍[http://blog.csdn.net/jiangchao858/article/details/54989025]Analyzer负责把文本字段转成token stream，然后自己处理、或调用Tokenzier和Filter进一步处理，Tokenizer和Filter是同等级和顺序执行的关系，一个处理完后交给下一个处理。Tokenizer接收text（从solr那里获得一个Reader来读取文本），拆分成tokens，输出token streamFilter接收token stream，对每个token进行处理（比如：替换、丢弃、不理），输出token stream。在配置文件中，Tokenizer放在第一位，Filter放在第二位直到最后一位。Filters是顺序执行的，前一个的结果是后一个是输入，所以，一般通用的处理放在前面，特殊的处理靠后###常见的Solr Filter过滤器ASCII Folding Filter这个Filter将不属于ASCII（127个字符，包括英文字母，数字，常见符号）的字符转化成与ASCII 字符等价的字符。没有参数。例如：123&lt;analyzer&gt; &lt;filter class="solr.ASCIIFoldingFilterFactory"/&gt;&lt;/analyzer&gt;输入： “á”输出：“a”####Classic Filter这个Filter接受Classic Tokenizer的结果，并处理首字母缩略词和所有格形式(英文中含有 ‘s 的形式)例如：1234&lt;analyzer&gt; &lt;tokenizer class="solr.ClassicTokenizerFactory"/&gt; &lt;filter class="solr.ClassicFilterFactory"/&gt;&lt;/analyzer&gt;原始文本：“I.B.M. cat’s can’t”输入： “I.B.M”, “cat’s”, “can’t”输出：“IBM”, “cat”, “can’t”####Common Grams Filter这个Filter结合通用tokens来处理常用词。| 参数 | 值 | 说明 || ——– | ——- | —- || words | 以.txt结尾的文件| 提供常用词库 || format | 可选，例如”snowball” | 指定常用词列表的格式 || ignoreCase | 布尔值，默认false | 是否忽略常用词大小写 |例如：1234&lt;analyzer&gt; &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt; &lt;filter class="solr.CommonGramsFilterFactory" words="stopwords.txt" ignoreCase="true"/&gt;&lt;/analyzer&gt;原始文本： “the Cat”输入： “the”, “Cat”输出： “the_cat”####Edge N-Gram Filter将输入文本转化成指定范围大小的片段。| 参数 | 值 | 说明 || ——– | ——- | —- || minGramSize | 整数，默认1| 指定最小的片段大小 || maxGramSize | 整数，默认1 | 指定最大的片段大小 |例如：1234&lt;analyzer&gt; &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt; &lt;filter class="solr.EdgeNGramFilterFactory"/&gt;&lt;/analyzer&gt;原始文本： “four score and twenty”输入： “four”, “score”, “and”, “twenty”输出： “f”, “s”, “a”, “t”例子：1234&lt;analyzer&gt; &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt; &lt;filter class="solr.EdgeNGramFilterFactory" minGramSize="1" maxGramSize="4"/&gt;&lt;/analyzer&gt;原始文本： “four score”输入： “four”, “score”输出： “f”, “fo”, “fou”, “four”, “s”, “sc”, “sco”, “scor”例子：1234&lt;analyzer&gt; &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt; &lt;filter class="solr.EdgeNGramFilterFactory" minGramSize="4" maxGramSize="6"/&gt;&lt;/analyzer&gt;原始文本： “four score and twenty”输入： “four”, “score”, “and”, “twenty”输出： “four”, “scor”, “score”, “twen”, “twent”, “twenty”####English Minimal Stem Filter这个Filter将英语中的复数处理成单数形式。没有参数。例子：1234&lt;analyzer type="index"&gt; &lt;tokenizer class="solr.StandardTokenizerFactory "/&gt; &lt;filter class="solr.EnglishMinimalStemFilterFactory"/&gt;&lt;/analyzer&gt;原始文本： “dogs cats”输入： “dogs”, “cats”输出： “dog”, “cat”####Keep Word Filter这个Filter将不属于列表中的单词过滤掉。和Stop Words Filter的效果相反。| 参数 | 值 | 说明 || ——– | ——- | —- || words | 必填，以.txt结尾的文件| 提供保留词列表 || ignoreCase | 布尔值，默认false | 是否忽略常用词大小写 || enablePositionIncrements | 布尔值 | Solr5.0以后废弃 |例子：1234&lt;analyzer&gt; &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt; &lt;filter class="solr.KeepWordFilterFactory" words="keepwords.txt"/&gt;&lt;/analyzer&gt;保留词列表keepwords.txthappyfunnysilly原始文本： “Happy, sad or funny”输入： “Happy”, “sad”, “or”, “funny”输出： “funny”例子：1234&lt;analyzer&gt; &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt; &lt;filter class="solr.KeepWordFilterFactory" words="keepwords.txt" ignoreCase="true"/&gt;&lt;/analyzer&gt;保留词列表keepwords.txthappyfunnysilly原始文本： “Happy, sad or funny”输入： “Happy”, “sad”, “or”, “funny”输出： “Happy”, “funny”例子：12345&lt;analyzer&gt; &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt; &lt;filter class="solr.LowerCaseFilterFactory"/&gt; &lt;filter class="solr.KeepWordFilterFactory" words="keepwords.txt"/&gt;&lt;/analyzer&gt;保留词列表keepwords.txthappyfunnysilly原始文本： “Happy, sad or funny”输入： “happy”, “sad”, “or”, “funny”输出： “Happy”, “funny”####Length Filter这个Filter处理在给定范围长度的tokens。| 参数 | 值 | 说明 || ——– | ——- | —- || min | 整数，必填| 指定最小的token长度 || max | 整数，必填，需大于min | 指定最大的token长度 || enablePositionIncrements | 布尔值 | Solr5.0以后废弃 |例子：1234&lt;analyzer&gt; &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt; &lt;filter class="solr.LengthFilterFactory" min="3" max="7"/&gt;&lt;/analyzer&gt;原始文本： “turn right at Albuquerque”输入： “turn”, “right”, “at”, “Albuquerque”输出： “turn”, “right”####Lower Case Filter这个Filter将所有的大写字母转化为小写。没有参数。例子：1234&lt;analyzer&gt; &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt; &lt;filter class="solr.LowerCaseFilterFactory"/&gt;&lt;/analyzer&gt;原始文本： “Down With CamelCase”输入： “Down”, “With”, “CamelCase”输出： “down”, “with”, “camelcase”####N-Gram Filter将输入文本转化成指定范围大小的片段。| 参数 | 值 | 说明 || ——– | ——- | —- || minGramSize | 整数，默认1| 指定最小的片段大小 || maxGramSize | 整数，默认2 | 指定最大的片段大小 |例子：1234&lt;analyzer&gt; &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt; &lt;filter class="solr.NGramFilterFactory"/&gt;&lt;/analyzer&gt;原始文本： “four score”输入： “four”, “score”输出： “f”, “o”, “u”, “r”, “fo”, “ou”, “ur”, “s”, “c”, “o”, “r”, “e”, “sc”, “co”, “or”, “re”例子2：1234&lt;analyzer&gt; &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt; &lt;filter class="solr.NGramFilterFactory" minGramSize="1" maxGramSize="4"/&gt;&lt;/analyzer&gt;原始文本： “four score”输入： “four”, “score”输出： “f”, “fo”, “fou”, “four”, “s”, “sc”, “sco”, “scor”例子3：1234&lt;analyzer&gt; &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt; &lt;filter class="solr.NGramFilterFactory" minGramSize="3" maxGramSize="5"/&gt;&lt;/analyzer&gt;原始文本： “four score”输入： “four”, “score”输出： “fou”, “four”, “our”, “sco”, “scor”, “score”, “cor”, “core”, “ore”####Pattern Replace Filter这个Filter可以使用正则表达式来替换token的一部分内容，与正则表达式想匹配的被替换，不匹配的不变。| 参数 | 值 | 说明 || ——– | ——- | —- || pattern | 必填，正则表达式| 需要匹配的正则表达式 || replacement | 必填，字符串 | 需要替换的部分 || replace | “all” 或 “first”, 默认”all” | 全部替换还是，只替换第一个 |例子：1234&lt;analyzer&gt; &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt; &lt;filter class="solr.PatternReplaceFilterFactory" pattern="cat" replacement="dog"/&gt;&lt;/analyzer&gt;原始文本： “cat concatenate catycat”输入： “cat”, “concatenate”, “catycat”输出： “dog”, “condogenate”, “dogydog”例子2：1234&lt;analyzer&gt; &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt; &lt;filter class="solr.PatternReplaceFilterFactory" pattern="cat" replacement="dog" replace="first"/&gt;&lt;/analyzer&gt;原始文本： “cat concatenate catycat”输入： “cat”, “concatenate”, “catycat”输出： “dog”, “condogenate”, “dogycat”例子3：1234&lt;analyzer&gt; &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt; &lt;filter class="solr.PatternReplaceFilterFactory" pattern="(\D+)(\d+)$" replacement="$1_$2"/&gt;&lt;/analyzer&gt;原始文本： “cat foo1234 9987 blah1234foo”输入： “cat”, “foo1234”, “9987”, “blah1234foo”输出： “cat”, “foo_1234”, “9987”, “blah1234foo”####Standard Filter这个Filter将首字母缩略词中的点号（如I.B.M处理为IBM）去除，将英文中的所有格形式中的’s除去（如stationer’s处理为stationer）。没有参数。在Solr3.1以后已经废弃####Stop Filter这个Filter会在解析时忽略给定的停词列表（stopwords.txt）中的内容。| 参数 | 值 | 说明 || ——– | ——- | —- || words | 可选，停词列表| 指定停词列表的路径 || format | 可选，如”snowball” | 停词列表的格式 || ignoreCase | 布尔值，默认false | 是否忽略大小写 || enablePositionIncrements | 布尔值 | Solr5.0以后废弃 |例子：1234&lt;analyzer&gt; &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt; &lt;filter class="solr.StopFilterFactory" words="stopwords.txt"/&gt;&lt;/analyzer&gt;保留词列表stopwords.txtbeorto原始文本： “To be or what?”输入： “To”(1), “be”(2), “or”(3), “what”(4)输出： “To”(1), “what”(4)例子2：1234&lt;analyzer&gt; &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt; &lt;filter class="solr.StopFilterFactory" words="stopwords.txt" ignoreCase="true"/&gt;&lt;/analyzer&gt;保留词列表stopwords.txtbeorto原始文本： “To be or what?”输入： “To”(1), “be”(2), “or”(3), “what”(4)输出： “what”(4)####Synonym Filter这个Filter用来处理同义词。| 参数 | 值 | 说明 || ——– | ——- | —- || synonyms | 必选，以.txt结尾的文件| 指定同义词列表 || ignoreCase | 布尔值，默认false | 是否忽略大小写 || expand | 布尔值，默认true | TRUE：同义词将扩大至所有等价的同义词；FALSE：所有等价的同义词将相当于列表中的第一个。 || format | 可选，默认solr | 指定解析同义词的策略 || tokenizerFactory | 可选，默认WhitespaceTokenizerFactory | 指定解析同义词列表使用的tokenizer factory || analyzer | 可选，默认WhitespaceTokenizerFactory | 指定使用的analyzer class |注意，常用的同义词列表格式：以#开头的行为注释内容，忽略以,分隔的文本，为双向同义词，左右内容等价，互为同义词以=&gt;分隔的文本，为单向同义词，匹配到左边内容，将替换为右边内容，反之不成立例子：1234&lt;analyzer&gt; &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt; &lt;filter class="solr.SynonymFilterFactory" synonyms="mysynonyms.txt"/&gt;&lt;/analyzer&gt;同义词列表synonyms.txtcouch,sofa,divanteh =&gt; thehuge,ginormous,humungous =&gt; largesmall =&gt; tiny,teeny,weeny原始文本： “teh small couch”输入： “teh”(1), “small”(2), “couch”(3)输出： “the”(1), “tiny”(2), “teeny”(2), “weeny”(2), “couch”(3), “sofa”(3), “divan”(3)原始文本： “teh ginormous, humungous sofa”输入： “teh”(1), “ginormous”(2), “humungous”(3), “sofa”(4)输出： “the”(1), “large”(2), “large”(3), “couch”(4), “sofa”(4), “divan”(4)####Word Delimiter Filter这个Filter以每个单词为分隔符。| 参数 | 值 | 说明 |举例|| ——– | ——- | —- | —- || generateWordParts | 整数，默认1| 不为0的时候正常分词 |CamelCase -&gt; “Camel”, “Case”|| generateNumberParts | 整数，默认1| 不为0的时候可以分隔数字 |“1947-32” -&gt;”1947”, “32”|| splitOnCaseChange | 整数，默认1| 为0时，不处理驼峰拼写形式 |“BugBlaster-XL” -&gt; “BugBlaster”,”XL”|| splitOnNumerics | 整数，默认1| 为0时，不处理数字和单词组合的形式 |“FemBot3000” -&gt; “Fem”, “Bot3000”|| catenateWords |整数，默认0| 不为0时，会将分析后的单词连接在一起 |“hot-spot-sensor’s” -&gt; “hotspotsensor”|| catenateNumbers |整数，默认0| 不为0时，会将分析后的数字连接在一起 |1947-32 -&gt; “194732”|| catenateAll |0或1，默认0| 不为0时，会将分析后的单词、数字等连接在一起 |“Zap-Master-9000” -&gt; “ZapMaster9000”|| preserveOriginal |整数，默认0| 不为0时，将保留原始的token |“Zap-Master-9000” -&gt; “Zap-Master-9000”, “Zap”, “Master”, “9000”|| protected |可选，路径名| 某个文件的内容将不会分析 ||| stemEnglishPossessive |整数，默认1| 为1时，将除去’s形式 |“O’Reilly’s” -&gt; “O”, “Reilly”|例子：1234&lt;analyzer&gt; &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt; &lt;filter class="solr.WordDelimiterFilterFactory"/&gt;&lt;/analyzer&gt;原始文本： “hot-spot RoboBlaster/9000 100XL”输入： “hot-spot”, “RoboBlaster/9000”, “100XL”输出： “hot”, “spot”, “Robo”, “Blaster”, “9000”, “100”, “XL”例子2：1234&lt;analyzer&gt; &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt; &lt;filter class="solr.WordDelimiterFilterFactory" generateNumberParts="0" splitOnCaseChange="0"/&gt;&lt;/analyzer&gt;原始文本： “hot-spot RoboBlaster/9000 100-42”输入： “hot-spot”, “RoboBlaster/9000”, “100-42”输出： “hot”, “spot”, “RoboBlaster”, “9000”,”100”,”42”例子3：1234&lt;analyzer&gt; &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt; &lt;filter class="solr.WordDelimiterFilterFactory" catenateWords="1" catenateNumbers="1"/&gt;&lt;/analyzer&gt;原始文本： “hot-spot 100+42 XL40”输入： “hot-spot”(1), “100+42”(2), “XL40”(3)输出： “hot”(1), “spot”(2), “hotspot”(2), “100”(3), “42”(4), “10042”(4), “XL”(5), “40”(6)例子4：1234&lt;analyzer&gt; &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt; &lt;filter class="solr.WordDelimiterFilterFactory" catenateAll="1"/&gt;&lt;/analyzer&gt;原始文本： “XL-4000/ES”输入： “XL-4000/ES”(1)输出： “XL”(1), “4000”(2), “ES”(3), “XL4000ES”(3)例子5：1234&lt;analyzer&gt; &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt; &lt;filter class="solr.WordDelimiterFilterFactory" protected="protwords.txt"/&gt;&lt;/analyzer&gt;受保护词列表protwords.txtAstroBlasterXL-5000原始文本： “FooBar AstroBlaster XL-5000 ==ES-34-”输入： “FooBar”, “AstroBlaster”, “XL-5000”, “==ES-34-”输出： “FooBar”, “AstroBlaster”, “XL-5000”, “ES”, “34”]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[tomcat-load-jsp]]></title>
      <url>%2F2017%2F03%2F30%2Ftomcat-load-jsp%2F</url>
      <content type="text"><![CDATA[tomcat解决加载JSP文件过大错误标签（tomcat jsp ）： tomcat当遇到多个Jsp include一起的时候加载时遇到如下错误：Error：SEVERE: Servlet.service() for servlet jsp threw exception org.apache.jasper.JasperException: Unable to compile class for JSP: An error occurred at line: [136] in the generated java file: **** The code of method _jspService(HttpServletRequest, HttpServletResponse) is exceeding the 65535 bytes limit 解决：1.修改tomcat配置：打开tomcat路径—conf—web.xml。2.直接搜索关键字‘xpoweredBy’再加一个init-param初始化参数配置如下：&lt;servlet&gt; &lt;servlet-name&gt;jsp&lt;/servlet-name&gt; &lt;servlet-class&gt;org.apache.jasper.servlet.JspServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;genStrAsCharArray&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;mappedfile&lt;/param-name&gt; &lt;param-value&gt;false&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;development&lt;/param-name&gt; &lt;param-value&gt;false&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;fork&lt;/param-name&gt; &lt;param-value&gt;false&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;xpoweredBy&lt;/param-name&gt; &lt;param-value&gt;false&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;3&lt;/load-on-startup&gt; &lt;/servlet&gt; 3.保存退出，删除eclipse中的tomcat配置重新添加即可。4.注意大小写mappedfile]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[liferay-quartz]]></title>
      <url>%2F2017%2F03%2F30%2Fliferay-quartz%2F</url>
      <content type="text"><![CDATA[Liferay Quartz标签（liferay quartz）： liferayliferay 定时任务的Listener12345678&lt;scheduler-entry&gt; &lt;scheduler-event-listener-class&gt;com.*.quartz.ClearEmailStorageMessageListener&lt;/scheduler-event-listener-class&gt; &lt;trigger&gt; &lt;cron&gt; &lt;cron-trigger-value&gt;0 0 23 * * ?&lt;/cron-trigger-value&gt; &lt;/cron&gt; &lt;/trigger&gt; &lt;/scheduler-entry&gt;表达式 含义“0 0 12 ?” 每天中午十二点触发“0 15 10 ? “ 每天早上10：15触发“0 15 10 ?” 每天早上10：15触发“0 15 10 ? “ 每天早上10：15触发“0 15 10 ? 2005” 2005年的每天早上10：15触发“0 14 ?” 每天从下午2点开始到2点59分每分钟一次触发“0 0/5 14 ?” 每天从下午2点开始到2：55分结束每5分钟一次触发“0 0/5 14,18 ?” 每天的下午2点至2：55和6点至6点55分两个时间段内每5分钟一次触发“0 0-5 14 ?” 每天14:00至14:05每分钟一次触发“0 10,44 14 ? 3 WED” 三月的每周三的14：10和14：44触发“0 15 10 ? MON-FRI” 每个周一、周二、周三、周四、周五的10：15触发“0 15 10 15 ?” 每月15号的10：15触发“0 15 10 L * ?” 每月的最后一天的10：15触发]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[liferay_searching]]></title>
      <url>%2F2017%2F03%2F01%2Fliferay-searching%2F</url>
      <content type="text"><![CDATA[Searching in Liferay 6.2标签（liferay,search）： liferay,searchliferay search 底层是基于lucene进行关键字搜索,在企业开发我们都会选择solr集成。通常客户在查询content时，不需要显示出过多的content（因为默认的分词是或者的关系）,这个时候我们一般需要更精确的搜所：&quot;liferay&quot; AND &quot;kaleo workflow&quot;这样我们就会查询既包含liferay的关键字也包含kaleo workflow的关键字的content。12345678910111213BooleanQuery keyWordsQuery = BooleanQueryFactoryUtil.create(searchContext); keyWords=escapeQueryCharsAnd(keyWords); String[] keyarr=keyWords.split(" "); StringBuilder sb = new StringBuilder(); int i=0; for(String keyword:keyarr)&#123; keyword="\""+keyword+"\""; sb.append(keyword); if(i&lt;keyarr.length-1)&#123; sb.append(" AND "); &#125; i++;&#125;这个escapeQueryCharsAnd方法的实现：123456789101112131415public String escapeQueryChars(String s) &#123; StringBuilder sb = new StringBuilder(); for (int i = 0; i &lt; s.length(); i++) &#123; char c = s.charAt(i); // These characters are part of the query syntax and must be escaped if (c == '\\' || c == '+' || c == '-' || c == '!' || c == '(' || c == ')' || c == ':'|| c == '^' || c == '[' || c == ']' || c == '\"' || c == '&#123;' || c == '&#125;' || c == '~'|| c == '*' || c == '?' || c == '|' || c == '&amp;' || c == ';' || c == '/'|| Character.isWhitespace(c)) &#123; sb.append('\\'); &#125; sb.append(c); &#125; return sb.toString(); &#125;]]></content>
    </entry>

    
  
  
</search>
